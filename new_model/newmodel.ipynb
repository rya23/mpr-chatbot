{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_parquet(\"hf://datasets/pankajemplay/llama-intent-1615/data/train-00000-of-00001-b2b83bc2e0f680a6.parquet\")\n",
    "df = pd.read_csv(\"intent.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Query</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Bot Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>welcome</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to cancel my order</td>\n",
       "      <td>order detail</td>\n",
       "      <td>Please provide the order number or deal ID to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not satisfied with this.</td>\n",
       "      <td>raise question</td>\n",
       "      <td>I'm sorry to hear that. How can I assist you f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where can I find the user manual?</td>\n",
       "      <td>search</td>\n",
       "      <td>Searching for the user manual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How's the weather today?</td>\n",
       "      <td>small talk</td>\n",
       "      <td>I'm not sure about the current weather.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          User Query          Intent  \\\n",
       "0                              Hello         welcome   \n",
       "1          I want to cancel my order    order detail   \n",
       "2       I'm not satisfied with this.  raise question   \n",
       "3  Where can I find the user manual?          search   \n",
       "4           How's the weather today?      small talk   \n",
       "\n",
       "                                        Bot Response  \n",
       "0                 Hello! How can I assist you today?  \n",
       "1  Please provide the order number or deal ID to ...  \n",
       "2  I'm sorry to hear that. How can I assist you f...  \n",
       "3                   Searching for the user manual...  \n",
       "4            I'm not sure about the current weather.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"User Query\",\"Intent\",\"Bot Response\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Query</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Bot Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>welcome</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to cancel my order</td>\n",
       "      <td>order detail</td>\n",
       "      <td>Please provide the order number or deal ID to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not satisfied with this.</td>\n",
       "      <td>raise question</td>\n",
       "      <td>I'm sorry to hear that. How can I assist you f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where can I find the user manual?</td>\n",
       "      <td>search</td>\n",
       "      <td>Searching for the user manual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How's the weather today?</td>\n",
       "      <td>small talk</td>\n",
       "      <td>I'm not sure about the current weather.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          User Query          Intent  \\\n",
       "0                              Hello         welcome   \n",
       "1          I want to cancel my order    order detail   \n",
       "2       I'm not satisfied with this.  raise question   \n",
       "3  Where can I find the user manual?          search   \n",
       "4           How's the weather today?      small talk   \n",
       "\n",
       "                                        Bot Response  \n",
       "0                 Hello! How can I assist you today?  \n",
       "1  Please provide the order number or deal ID to ...  \n",
       "2  I'm sorry to hear that. How can I assist you f...  \n",
       "3                   Searching for the user manual...  \n",
       "4            I'm not sure about the current weather.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('intent.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1615 entries, 0 to 1614\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   User Query    1615 non-null   object\n",
      " 1   Intent        1615 non-null   object\n",
      " 2   Bot Response  1615 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 38.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to intents.json completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Initialize a dictionary to store intents\n",
    "intents_dict = defaultdict(lambda: {\"patterns\": [], \"responses\": []})\n",
    "\n",
    "# Iterate over the DataFrame rows to fill the dictionary\n",
    "for _, row in df.iterrows():\n",
    "    intent = row['Intent']\n",
    "    user_query = row['User Query']\n",
    "    bot_response = row['Bot Response']\n",
    "    \n",
    "    # Append the user query (pattern) and response to the corresponding intent\n",
    "    intents_dict[intent][\"patterns\"].append(user_query)\n",
    "    intents_dict[intent][\"responses\"].append(bot_response)\n",
    "\n",
    "# Convert the intents dictionary into the desired JSON format\n",
    "intents_json = {\"intents\": [{\"intent\": intent, \"patterns\": data[\"patterns\"], \"responses\": data[\"responses\"]} for intent, data in intents_dict.items()]}\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open('intents.json', 'w') as json_file:\n",
    "    json.dump(intents_json, json_file, indent=4)\n",
    "\n",
    "print(\"Conversion to intents.json completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1615 entries, 0 to 1614\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   User Query    1615 non-null   object\n",
      " 1   Intent        1615 non-null   object\n",
      " 2   Bot Response  1615 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 38.0+ KB\n",
      "None\n",
      "Batch of Queries (BoW): tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Batch of Intents: tensor([7, 2, 9, 2, 0, 2, 4, 8, 7, 6, 9, 3, 4, 9, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Load the CSV data\n",
    "# Assuming you have a CSV file with columns: 'User Query', 'Intent', 'Bot Response'\n",
    "# file_path = 'your_file.csv'  # Replace with the actual file path\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the data\n",
    "print(df.info())  # Shows dataframe structure and memory usage\n",
    "\n",
    "# 2. Tokenize and Vectorize using Bag-of-Words (BoW)\n",
    "vectorizer = CountVectorizer()  # You can also use TF-IDF by replacing this with TfidfVectorizer\n",
    "X = vectorizer.fit_transform(df['User Query']).toarray()  # Tokenize and convert to BoW vectors\n",
    "\n",
    "# 3. Label Encoding for Intent column\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Intent'])  # Convert intents to numerical labels\n",
    "\n",
    "# 4. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# 5. Create a Custom Dataset class for PyTorch\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, queries, intents):\n",
    "        self.queries = queries\n",
    "        self.intents = intents\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.queries[idx], self.intents[idx]\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = ChatbotDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = ChatbotDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# 6. Create DataLoaders for batching\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Sample output to verify\n",
    "for queries, intents in train_loader:\n",
    "    print(\"Batch of Queries (BoW):\", queries)\n",
    "    print(\"Batch of Intents:\", intents)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1539 11\n",
      "Epoch [1/10], Loss: 2.0753\n",
      "Accuracy on test set: 81.11%\n",
      "Model saved as chatbot_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Define the Model\n",
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ChatbotModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 128)  # Hidden layer with 128 units\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(128, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Set parameters\n",
    "input_size = X_train.shape[1]  # Number of features (vocabulary size)\n",
    "num_classes = len(label_encoder.classes_)  # Number of unique intents\n",
    "print(input_size,num_classes)\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatbotModel(input_size, num_classes)\n",
    "\n",
    "# 2. Set Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "# 3. Training Loop\n",
    "num_epochs = 10  # Number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for queries, intents in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(queries)  # Forward pass\n",
    "        loss = criterion(outputs, intents)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "    if epoch %10 ==0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "# 4. Evaluation\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for queries, intents in test_loader:\n",
    "        outputs = model(queries)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "        total += intents.size(0)  # Total samples\n",
    "        correct += (predicted == intents).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'chatbot_model.pth')\n",
    "print(\"Model saved as chatbot_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare the test input\n",
    "def preprocess_input(user_input):\n",
    "    # Transform user input into the same format as training data\n",
    "    input_vector = vectorizer.transform([user_input]).toarray()\n",
    "    return torch.tensor(input_vector, dtype=torch.float32)\n",
    "\n",
    "# 2. Make Predictions\n",
    "def predict_intent(user_input):\n",
    "    model.eval()  # Set the model to evaluation mode\\\n",
    "    with torch.no_grad():\n",
    "        input_tensor = preprocess_input(user_input)\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        return label_encoder.inverse_transform(predicted.numpy())[0]\n",
    "\n",
    "# 3. Retrieve Responses\n",
    "def get_bot_response(intent):\n",
    "    response = df[df['Intent'] == intent]['Bot Response'].values[0]\n",
    "    return response\n",
    "\n",
    "# 4. Interactive Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready to chat! Type 'exit' to end.\n",
      "You : exit\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready to chat! Type 'exit' to end.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    print(f\"You : {user_input}\")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    predicted_intent = predict_intent(user_input)\n",
    "    bot_response = get_bot_response(predicted_intent)\n",
    "    print(\"Bot:\", bot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4891/4275302497.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('chatbot_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your trained model\n",
    "input_size = 1539  # This should be set to the size of your input features\n",
    "num_classes = 11  # This should be set to the number of classes in your label encoder\n",
    "\n",
    "model = ChatbotModel(input_size, num_classes)\n",
    "model.load_state_dict(torch.load('chatbot_model.pth'))\n",
    "model.eval()  # Set model to eval mode\n",
    "\n",
    "# Load your CSV with Intent and Bot Response\n",
    "df = pd.read_csv('intent.csv')  # Replace with actual CSV path\n",
    "\n",
    "# Simulating vectorizer and label encoder (you should load them if you have them saved)\n",
    "vectorizer = CountVectorizer()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Define FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Pydantic model for incoming user messages\n",
    "class Query(BaseModel):\n",
    "    message: str\n",
    "\n",
    "# Preprocess the user input (tokenization)\n",
    "def preprocess_input(user_input):\n",
    "    input_vector = vectorizer.transform([user_input]).toarray()\n",
    "    return torch.tensor(input_vector, dtype=torch.float32)\n",
    "\n",
    "# Predict intent\n",
    "def predict_intent(user_input):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = preprocess_input(user_input)\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        intent = label_encoder.inverse_transform(predicted.numpy())[0]\n",
    "        return intent\n",
    "\n",
    "# Get bot response for the predicted intent\n",
    "def get_bot_response(intent):\n",
    "    response = df[df['Intent'] == intent]['Bot Response'].values[0]\n",
    "    return response\n",
    "\n",
    "# Define the /chat/ endpoint for user messages\n",
    "@app.post(\"/chat/\")\n",
    "async def chat(query: Query):\n",
    "    user_message = query.message\n",
    "    predicted_intent = predict_intent(user_message)\n",
    "    bot_response = get_bot_response(predicted_intent)\n",
    "    return {\"intent\": predicted_intent, \"response\": bot_response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10517/1249130460.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('chatbot_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready to chat! Type 'exit' to end.\n",
      "You : hello\n",
      "Bot: Hello! How can I assist you today?\n",
      "You : hi\n",
      "Bot: Hello! How can I assist you today?\n",
      "You : hi\n",
      "Bot: Hello! How can I assist you today?\n",
      "You : order number 2\n",
      "Bot: Please provide the order number or deal ID to cancel.\n",
      "You : \n",
      "Bot: I'm not sure about the current weather.\n",
      "You : 1234\n",
      "Bot: I'm not sure about the current weather.\n",
      "You : \n",
      "Bot: I'm not sure about the current weather.\n",
      "You : exit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import torch.nn as nn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Define the model architecture again (must match the one used during training)\n",
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ChatbotModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 128)  # Hidden layer with 128 units\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(128, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Load your trained model\n",
    "input_size = 1539  # This should be set to the size of your input features\n",
    "num_classes = 11# This should be set to the number of classes in your label encoder\n",
    "\n",
    "model = ChatbotModel(input_size, num_classes)\n",
    "model.load_state_dict(torch.load('chatbot_model.pth'))\n",
    "model.eval()  # Set model to eval mode\n",
    "\n",
    "# Load your CSV with Intent and Bot Response\n",
    "df = pd.read_csv('intent.csv')  # Replace with actual CSV path\n",
    "\n",
    "# Simulating vectorizer and label encoder (you should load them if you have them saved)\n",
    "# vectorizer = CountVectorizer()\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "vectorizer = CountVectorizer()  # You can also use TF-IDF by replacing this with TfidfVectorizer\n",
    "X = vectorizer.fit_transform(df['User Query']).toarray()  # Tokenize and convert to BoW vectors\n",
    "\n",
    "# 3. Label Encoding for Intent column\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Intent'])\n",
    "\n",
    "\n",
    "# Preprocess the user input (tokenization)\n",
    "def preprocess_input(user_input):\n",
    "    input_vector = vectorizer.transform([user_input]).toarray()\n",
    "    return torch.tensor(input_vector, dtype=torch.float32)\n",
    "\n",
    "# Predict intent\n",
    "def predict_intent(user_input):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = preprocess_input(user_input)\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        intent = label_encoder.inverse_transform(predicted.numpy())[0]\n",
    "        return intent\n",
    "\n",
    "# Get bot response for the predicted intent\n",
    "def get_bot_response(intent):\n",
    "    response = df[df['Intent'] == intent]['Bot Response'].values[0]\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "print(\"Chatbot is ready to chat! Type 'exit' to end.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    print(f\"You : {user_input}\")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    user_input=repr(user_input)\n",
    "    predicted_intent = predict_intent(user_input)\n",
    "    bot_response = get_bot_response(predicted_intent)\n",
    "    print(\"Bot:\", bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
