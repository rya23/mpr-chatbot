{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rya23/llm-from-scratch/blob/master/first_ai_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YC6AAkQhx9v7",
        "outputId": "f4d808c7-f6ea-419d-b1e0-f917d4ed8f78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-06 17:31:08--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-08-06 17:31:08 (99.4 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Load the Dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "8ct3HGZbARJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "0hHsGA3IAGhl",
        "outputId": "b66e1d86-3ead-4227-9ec2-1197805b33a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt' , 'r',encoding ='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "vIT6lURnx-S3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:100]\n",
        "len(text)"
      ],
      "metadata": {
        "id": "2ZzYHXhTx-am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23656440-ca54-4884-e12a-fdb64abc9d9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print(''.join(chars))\n",
        "vocabulary_size = len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONx-jyqr3jYO",
        "outputId": "8401d8b5-b4ec-446c-b22c-e045774cf15c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s : [stoi[c] for c in s]\n",
        "decode = lambda s : ''.join([itos[c] for  c in s])"
      ],
      "metadata": {
        "id": "GcwrmKEn3PzW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"hello there\"))\n",
        "print(decode(encode(\"hello there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6xTMwG83P2P",
        "outputId": "b79eb96f-f070-429c-f706-06141fbbdfcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]\n",
            "hello there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text),dtype=torch.long)\n",
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKPywHEF3P7k",
        "outputId": "7db3fb5e-e099-44b2-9827-38d644081180"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
              "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
              "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
              "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
              "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ],
      "metadata": {
        "id": "JKyKcbs43P-V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bh6_839Q3QBM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8 # size of context to be trained\n",
        "batch_size = 4 # Independent Parallel data blocks to be loaded at once\n",
        "\n",
        "\n",
        "def generate_batch(split):\n",
        "\n",
        "    data = train_data if split == 'train' else test_data\n",
        "    random_points = torch.randint(len(data)-block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in random_points])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in random_points])\n",
        "\n",
        "    x,y = x.to(device),y.to(device)\n",
        "\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "vZa1eXieAJLC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = generate_batch('train')\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUntpdOm3QD8",
        "outputId": "740a2378-16a9-4334-be62-fe2a17bbac67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1, 40, 63,  1, 58, 46, 43,  1],\n",
            "        [61, 47, 52, 58, 43, 56,  5, 57],\n",
            "        [53, 56,  7,  7,  0,  0, 19, 24],\n",
            "        [54, 53, 57, 43, 42,  1, 58, 46]])\n",
            "tensor([[40, 63,  1, 58, 46, 43,  1, 57],\n",
            "        [47, 52, 58, 43, 56,  5, 57,  1],\n",
            "        [56,  7,  7,  0,  0, 19, 24, 27],\n",
            "        [53, 57, 43, 42,  1, 58, 46, 47]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logits are non normalized predictions which are fed to the softmax function"
      ],
      "metadata": {
        "id": "eWcwbD1SExil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BigramModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,vocabulary_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocabulary_size,vocabulary_size)\n",
        "\n",
        "    def forward(self,idx,targets = None): #idx are the random samples in the dataset\n",
        "        #targets is the expected value (idx is x  targets is y)\n",
        "        logits = self.token_embedding_table(idx) # of shape (B = Batch size , T = Time (block size) , C = Classes (vocab size))\n",
        "        if targets is None:\n",
        "            loss= None\n",
        "        else:\n",
        "            B,T,C = logits.shape\n",
        "            logits = logits.view(B*T,C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits,targets)\n",
        "\n",
        "        return logits,loss\n",
        "\n",
        "\n",
        "    def generate(self,idx,max_tokens):\n",
        "        # idx is B , T\n",
        "        for _ in range(max_tokens):\n",
        "            logits,loss = self(idx)\n",
        "            logits = logits[:,-1,:] # B , C\n",
        "            probability = F.softmax(logits,dim=-1)\n",
        "\n",
        "            idx_next = torch.multinomial(probability,num_samples=1) # B ,1\n",
        "\n",
        "            idx =  torch.cat((idx,idx_next),dim=1) # B ,C+1\n",
        "\n",
        "        return idx\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "blGvkmdo3QHd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = BigramModel(vocabulary_size)\n",
        "m = m.to(device)\n",
        "logits,loss = m(x,y)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "0MfluddS3QJ8",
        "outputId": "78e283bb-f91a-4565-f3a2-454e789bcb5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.6027, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1,1),dtype = torch.long) , max_tokens = 20)[0].tolist()))"
      ],
      "metadata": {
        "id": "2gxErDtt2WTT",
        "outputId": "5a253563-5576-48b4-9cbd-7abd03159c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "vCSev ?T- &v$YKZUNmY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "Owpl7eO53QMv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "max_iters= 3000\n",
        "eval_iters=200\n",
        "eval_interval = 300"
      ],
      "metadata": {
        "id": "l6W4sv6N3QP4"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "\n",
        "    if iter%eval_interval==0:\n",
        "\n",
        "        loss = calculate_loss()\n",
        "        print(f\"Iteration : {iter} Training Loss : {loss['train']} Validation Loss : {loss['val']}\")\n",
        "\n",
        "    xb,yb = generate_batch('train')\n",
        "\n",
        "    logits,loss = m(xb,yb)\n",
        "    optimizer.zero_grad(set_to_none=False)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "KYQs9ztTCSME",
        "outputId": "a5ead591-b231-4d26-aed9-4e3cb9f14756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration : 0 Training Loss : 2.4675893783569336 Validation Loss : 2.4890668392181396\n",
            "Iteration : 300 Training Loss : 2.4678900241851807 Validation Loss : 2.4856951236724854\n",
            "Iteration : 600 Training Loss : 2.4672842025756836 Validation Loss : 2.4812521934509277\n",
            "Iteration : 900 Training Loss : 2.4628500938415527 Validation Loss : 2.4841713905334473\n",
            "Iteration : 1200 Training Loss : 2.4638962745666504 Validation Loss : 2.4822094440460205\n",
            "Iteration : 1500 Training Loss : 2.4603497982025146 Validation Loss : 2.4743521213531494\n",
            "Iteration : 1800 Training Loss : 2.4552009105682373 Validation Loss : 2.481659173965454\n",
            "Iteration : 2100 Training Loss : 2.4576921463012695 Validation Loss : 2.484069347381592\n",
            "Iteration : 2400 Training Loss : 2.464855909347534 Validation Loss : 2.483203649520874\n",
            "Iteration : 2700 Training Loss : 2.4564592838287354 Validation Loss : 2.485264539718628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1),dtype=torch.long , device = device)"
      ],
      "metadata": {
        "id": "b0oa4iQpAk6N"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = context , max_tokens = 200)[0].tolist()))"
      ],
      "metadata": {
        "id": "J5pCgdiR3QS0",
        "outputId": "780a5a02-7b92-4e83-953c-f541ab4cd053",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HllirsaE:\n",
            "Handith Filfome hon w s f s CLA n ctehtilowat g:\n",
            "Julse; LA:\n",
            "s.\n",
            "\n",
            "\n",
            "Ththatowend ay d, Tuat 'stof ply,\n",
            "\n",
            "Resowe itc, I tsith dushly hisire me t wnctis ju wory wienthe n, wis my'stemisthan, cus ac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFZOH5tLBj2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "\n",
        "\n",
        "def calculate_loss():\n",
        "\n",
        "    out = {}\n",
        "    model = m.eval()\n",
        "\n",
        "    for split in ['train','val']:\n",
        "\n",
        "        losses = torch.zeros(eval_iters)\n",
        "\n",
        "        for k in range(eval_iters):\n",
        "            X,Y = generate_batch(split)\n",
        "            logits,loss = m(X,Y)\n",
        "            losses[k]=loss.item()\n",
        "        out[split]=losses.mean()\n",
        "    model.train()\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "xTX5qqos3QVr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZF9lAEw3QYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "xPOY33jF3Qbe",
        "outputId": "35006cc3-0d35-4a62-acfa-099fecf80fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7hSs5mAA3Qer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMHHM4033QhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnPuJL8t3Qkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRTuMJCd3QnF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}